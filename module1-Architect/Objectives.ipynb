{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 01 - Describe the Foundational Components of a Neural Network\n",
    "## Overview\n",
    "Later in this module, we will use a few handy tools to architect and train neural networks. But before we dive into that, we need to understand much more basic concepts of neural networks. As you can see from the name, neural networks use neurons, a digital-analog of a biological neuron. These neurons are linked or networked in a certain way to form a neural network. Essentially, a neural network is a computational model that works similarly to the human (or animal) brain.\n",
    "\n",
    "Neural networks range from simple single-layer perceptrons to complex ones with many hidden layers composed of many neurons. The complexity of the neural network depends on the dataset and the problem to solve.\n",
    "\n",
    "### Perceptron\n",
    "A neuron can be a single unit that accepts input (data) and provides output. The value of the output depends on the activation threshold of the neuron. The neuron will \"fire\" if the input is above the threshold; otherwise, the output is zero.\n",
    "\n",
    "The input to this perceptron is the data multiplied by a set of weights. The weights are updated for each iteration or pass through the network. The weighted input is then passed to the activation function. This function maps the input to the output, which depends on the function.\n",
    "\n",
    "We start with some input data and a set of weights to apply to that data. The one part we haven't mentioned yet is how a neural network learns. On the first iteration, the weights are selected randomly. Then, the weights are adjusted after the calculated results are compared to the expected results (using training data). Finally, these new weights are used to calculate the weighted sum, new results are calculated, and so on for the number of iterations specified.\n",
    "\n",
    "## Follow Along\n",
    "Let's implement a simple single-layer perceptron to explain better what we learned in the overview. It will be easier to understand how the different components of a neural network fit together with some example code.\n",
    "\n",
    "In the following example, we'll describe and implement the following parts of a neural network:\n",
    "\n",
    "- activation function\n",
    "- input data\n",
    "- weights\n",
    "- learning rate\n",
    "### Activation function\n",
    "The activation function maps the input to the output. This example uses a step function where the output is 0 if the sum of the weighted input is less than 0 and 1 otherwise. Again, a visualization of the function will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the activation function\n",
    "unit_step = lambda x: 0 if x < 0 else 1\n",
    "\n",
    "# Vectorize the function (use on an array)\n",
    "unit_step_v = np.vectorize(unit_step)\n",
    "\n",
    "# Create arrays to plot\n",
    "x = np.arange(-5, 5, 0.1)\n",
    "y = unit_step_v(x)\n",
    "\n",
    "# Plot\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('input'); plt.ylabel('step function output');\n",
    "\n",
    "# plt.clf() # comment/delete to show plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, -4, 8, 6, -5]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Empty set for reusability\n",
    "randomlist = []\n",
    "# Loop 5 times generating nums \n",
    "for i in range(0,5): # range 0 through 4\n",
    "\tn = random.randint(-10,10)\n",
    "\trandomlist.append(n)\n",
    "print(randomlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "def myfunc(a):\n",
    "    \"Return a-b if a>b, otherwise return a+b\"\n",
    "    if a > 2:\n",
    "        return bool(True)\n",
    "    else: return bool(False)\n",
    "# vectorize iterates function.\n",
    "vfunc = np.vectorize(myfunc)\n",
    "vfunc([1, 2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define some data to test, which in this case will be the logical OR operator: for input that includes a 1, the output is 1; otherwise, the output is 0. We'll consider an input array of two values so the possible choices are: [0,0], [0,1], [1,0], [1,1]. There is also a bias term, which is currently set to 1 for all inputs (we can use the bias to adjust the threshold; we will focus on the weights only first). The other part of the training data is the expected output, 0 for [0,0] and 1 for the rest of the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data ('OR' gate)\n",
    "# tuple format: ([x1, x2, bias], expected)\n",
    "training_data = [\n",
    "    (np.array([0,0,1]), 0),\n",
    "    (np.array([0,1,1]), 1),\n",
    "    (np.array([1,0,1]), 1),\n",
    "    (np.array([1,1,1]), 1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll code the perceptron. First, we'll initialize the weights using random numbers between 0 and 1. Then we'll set the learning rate as 0.2 (we'll learn more about the learning rate in the next module). We'll start with a low number of iterations so we can easily look through our output.\n",
    "# Perceptron code follows the example here, with\n",
    "# some modifications: \n",
    "# https://blog.dbrgn.ch/2013/3/26/perceptrons-in-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]: -0.1514812348736393 -> 0\n",
      "[0 1]: 0.52280979642973 -> 1\n",
      "[1 0]: 0.8052107186547842 -> 1\n",
      "[1 1]: 1.4795017499581538 -> 1\n"
     ]
    }
   ],
   "source": [
    "from random import choice   # Imports #for random input selection\n",
    "w = np.random.rand(3)       # Weights (begin with random weights)\n",
    "errors = []                 # Errors (store for plotting)\n",
    "learn_rate = 0.2            # Learning rate (the size of \"jumps\" when updating the weights)\n",
    "n = 50                      # Number of iterations/weight updates\n",
    "for i in range(n):          # \"Learning\" loop\n",
    "    x, expected = choice(training_data) # Select a random item from the training data\n",
    "    result = np.dot(w, x)   # Neuron calculation (dot product of weights and input)\n",
    "    error = expected - unit_step(result) # Compare to the expected result\n",
    "    errors.append(error)\n",
    "    w += learn_rate * error * x # Update the weights\n",
    "for x, _ in training_data:  # Test the perceptron with the \"learned\" weights\n",
    "    result = np.dot(x, w)\n",
    "    print(\"{}: {} -> {}\".format(x[:2], result, unit_step(result)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "197b4b3b7e4e7cf2cb1e2df97753f20b126ca79c47e8ad655a5130b1a1137e29"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
